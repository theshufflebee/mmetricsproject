---
title: "Read Me"
author: "Marcos Constantinou, Ryan Fellarhi & Jonas Bruno"
date: "Last edited: 12.05.2025"
site: bookdown::bookdown_site
documentclass: book
bibliography: [packages.bib, macroeconometrics_citations.bib] #name bib files
# url: your book url like https://bookdown.org/yihui/bookdown
# cover-image: path to the social sharing image like images/cover.jpg -> Do Later
description: |
  This is our website for a Universityproject. We put this together from a basic bookdown example so there might be some stuff in here from that.
link-citations: true           # optional but helpful for clickable citations
csl: apa.csl
github-repo: theshufflebee/mmetricsproject
---

# Readme {.unnumbered}

This is a Website for a class project from the 2025 Class Macroeconometrics at Université de Lausanne.

IMPORTANT: set wd to root/final -\> then use: bookdown::render_book("index.Rmd") to render site

## Usage {.unnumbered}

You can find all sections on the left. There is the Main Report which we hand in. This serves as a complete collection of the whole project to make sure everything is available to readers.

# Abstract {.unnumbered}

This Project assesses to what extent Financial Markets react to information provided by Donald Trump on Twitter and Truth Social. We asses the impact of posts on hourly volatility using ARMA-X. We evaluate multimple tie horizons and independent variables, such as if Trump posts anything, specific words such as tariff and sentiments. We then calculate IRFs and show that there are significant impacts on volatility.

<!--chapter:end:index.Rmd-->

---
bibliography: macroeconometrics_citations.bib  #
csl: apa.csl
link-citations: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r, warning=FALSE, echo=FALSE}
require("here")
require("stringr")
require("dplyr")
require("ggplot2")
require("lubridate")

truths_raw <- read.csv(here("data/mothership", "social.csv"))

truths <- truths_raw %>%
  mutate(
    # Use POSIX 'timestamp' directly
    date_time_parsed = as.POSIXct(timestamp, format = "%Y-%m-%d %H:%M:%S"),
    
    # Extract date only for plot
    day = as.Date(date_time_parsed),
    
    # Extract time only for plot
    time = format(date_time_parsed, "%H:%M"),
    
    # Convert time to numeric hours & minutes as fractions
    time_numeric = hour(date_time_parsed) + minute(date_time_parsed) / 60,
    
    # Shift time such that y = 0 corresponds to 12 PM
    time_shifted = time_numeric - 12
  )

```

# Introduction

Over the past 15 years social media has become an important
communications tool for politicians. One of the pioneers of this novel
approach has been Donald Trump, the 45th and 47th Presiden of the United
States. While he has been posting a lot online, he has increased posting
enourmously since he was banned from twitter after the Jan 6th riots.
This is on his own social media platform. As shown below he as been
posting constantly. [^1]

[^1]: Includes both Posts and Reposts

Especially in his second term he has been active on Truth Social for
long periods of time, often announcing or teasing important political
decision on there. Especially his announcement of "Now is a good time to
buy an hour before lifting reciprocal tariffs and him announcing his
post important Truth Social Post before Posting about price controls
lend to the fact that this has now become a major source of information.
Therefore the question wether financial markets react to these posts has
been discussed plenty. We investigate two research questions.

1)  Do Donald Trumps Posts impact market Volatility?
2)  Have traders learned from past actions and are now more reactive
    than they were during his first term?
    
\@ref(fig:fig1)

```{r fig1, warning=FALSE, echo=FALSE, fig.cap="Terminally Online: Trump's Twitter & Truth Social Posts (EDT)"}
 #Create the scatter plot
ggplot(truths, aes(x = day, y = time_shifted)) +
  geom_point(alpha = 0.5, color = "blue", shape = ".") +  # Transparancy to create "heatmap"
  scale_y_continuous(
    breaks = seq(-12, 12, by = 3),  # Custom Y scale
    labels = c("00:00", "03:00", "06:00", "09:00", "12:00", "15:00", "18:00", "21:00", "24:00")  # 24-hour format labels
  ) +
  labs(title = "Terminally Online: Trumps Twitter & Truth Social Posts (EDT)",
       x = "Date",
       y = "Time of Day") +
  theme_minimal() +
  
  
  # Customize X Axis
  scale_x_date(
    date_labels = "%b %Y",  # Format labels to show month and year
    date_breaks = "9 months"
  ) +
  
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  
  # Add vertical lines at 9:30 AM and 4:00 PM for stock market
  geom_hline(yintercept = (9 + 30 / 60) - 12, linetype = "longdash", color = "red") + 
  geom_hline(yintercept = 16 - 12, linetype = "dashed", color = "red") +   
  
  # theme adjustments
  theme(
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    panel.grid.major = element_line(linewidth = 0.5),  # Major gridlines
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```



## Literature Review

Information is one of the most valuable assets in the financial market.
Its importance lies at the core of the “Perfect Market Hypothesis”
(PMH), which states that the prices of assets fully reflect all
available information, adjusting immediately to any new data
@famaAdjustmentStockPrices2003 , and thereby creating a strong demand
for information flow. In addition, the “Mixture of Distribution
Hypothesis” states that the release of new information is closely linked
to movements in both realized and implied volatility (1)(3)(7).

Consequently, a large part of the literature had focused on the relation
between announcements, news and market activity. For example,
@schumakerTextualAnalysisStock2009 use various linguistic and textual
representations derived from financial news to predict stock market
prices. Similarly, @ederingtonHowMarketsProcess1993 analyze the impact
of macroeconomic news announcements on interest rate and foreign
exchange futures markets, particularly in terms of price changes and
volatility. Both studies, among others, find that prices— such as stock
prices—react primarily within minutes after the release of new
information.

Recently, the world has witnessed the rise of the Internet
which revolutionized the dissemination and accessibility of information.
Social media enable investors, analysts or politicians to instantly
share their information, news or opinions. This led some studies to
focus on the communication dynamics of social platform to predict
changes in the returns of financial assets (6)(8). In this context, the
impact of Trump’s tweets on various financial and macroeconomic
variables has been analysed by several studies, especially during his
first mandate.

Using high-frequency financial data,
@gjerstadPresidentTrumpsTweets2021 found an increase in uncertainty and
trading volume, along with a decline in the U.S. stock market—regardless
of the tweet's content. However, the effect was stronger when Trump used
confrontational words such as "tariff" or "trade war." Some of his
announcements also influenced the U.S. dollar exchange rate (l) and
certain market indices within minutes of the tweet being posted (r)(a).

Other scholars have shown that negative Trump’s tweets about specific
companies tended to reduce demand for their stocks (b)(g), whereas some
other have shown that they also impact market volatility indices such as
the VIX (w) or the Volfele(v). The effects of his tweets also extended
beyond the U.S.. For example, @nishimuraImpactsDonaldTrumps2025 shows a
positive relationship between volatility in European stock markets and
tweeter activity of Trump, and this effect tends to intensify as public
intention for his tweet grows (z).

<!--chapter:end:01-introduction.Rmd-->

---
bibliography: macroeconometrics_citations.bib  #
csl: apa.csl
link-citations: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r library_setup, results=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
rm(list=ls())
require(tinytex) #LaTeX
require(ggplot2) #plots
require(AEC) #JP-Renne functions
require(AER) #NW formula
require(forecast) #time series stuff
require(expm) #matrix exponents
require(here) #directory finder
require(stringr) # analysis of strings, important for the detection in tweets
require(dplyr) #data management
require(lubridate) #data dates management
require(zoo) #for lagging
require(jtools) #tables
require(huxtable) #tables
require(lmtest) #reg tests
require(vroom) #for loading data
require(data.table) #for data filtering
require(sysid) #for ARMA-X modeling
require(sandwich) #regression errors
require(stargazer) #nice reg tables
require(tidytext) #text mining
require(textstem) #lemmatization
require(quanteda) #tokenization
require(texreg) #arima tables
require(future.apply) #parallel computation (speed)
require(aTSA) #adf test
require(bookdown)

getwd()
#setwd("X:/Onedrive/Desktop/Macroeconometrics/R stuff/Project/mmetricsproject/final") 

#load helper functions
source(here("helperfunctions/data_loaders.R"))
source(here("helperfunctions/date_selector.R"))
source(here("helperfunctions/plotters.R"))
source(here("helperfunctions/quick_arma.R"))
source(here("helperfunctions/r.vol_calculators.R"))
source(here("helperfunctions/truths_cleaning_function.R"))
source(here("helperfunctions/armax_functions.R"))

```

```{r datasetup, results=FALSE, warning=FALSE, message=FALSE, echo=FALSE}

#load final dataset
source(here("helperfunctions/full_data.R"))

#load initial financial for plots
SPY <- read.csv(here("data/mothership", "SPY.csv"))
SPY$timestamp = as.POSIXct(SPY$timestamp,format = "%Y-%m-%d %H:%M:%S")
SPY = filter(SPY,between(timestamp, as.Date('2014-01-01'), as.Date('2025-05-07')))

#select timeframe 
data = filter(data,between(timestamp, as.Date('2014-01-01'), as.Date('2025-05-07')))

```

# Data

## Financial Data

For our financial data, we decided to try to find minute-by-minute prices for 
broad market indices. While the actual indices do not update their prices so often,
we had to take proxies under the form of ETF's that track them. Our 3 markets of
analysis are: SPY to track the S&P500, VGK to track the FTSE Developed Europe 
All Cap Index, and finally ASHR to track the CSI 300 China. We accessed this data
through a free stock API, Alpha Vantage. Our timeframe is from the first 
of January 2014 to the 7th of May 2025.


We then had to transform this data to get our main variable of interest, realised 
market volatility. We did so with the following formula:
$$
\begin{aligned}
  v_t = \frac{1}{N}&\sum_{i=1}^N(\Delta p_{t,i})^2 
\end{aligned}
$$
Where $\Delta p_t$ is the difference in price (open - close) and $i$ represents
every minute.

We used a custom function in order to get the average hourly volatility for each 
open market hour. Note that the first hour is from 9:30 am to 10:00 am since the 
market open on a half-hour but closes at 4:00 pm. We can plot this data in
<span style="color:red"> *figX* </span>.


```{r fin plots, message=FALSE, warning=FALSE, echo=FALSE}

price_plotter(SPY, title = "SPY Prices")

hvol_plotter(SPY, breaks = "yearly", title = "SPY Realised Volatility")

```



## Political Data

We have two sources for Trump's posts. The Tweets are from Kaggle
@DonaldTrumpTweets and go until the 8th of January 2021. Since he
switched his primary Posting platform to Truth Social we use only that
Data from 2021 onwards. All Truth Social Posts were scrapped from
trumpstruth.org, a webpage that aims to conserve all his posts. You can
find the dataset, and webscrapper, and Data cleaning process in the
Appendix.

Since we're using financial data that is constrained by trading hours,
we decided to move posts after 16:00 to the next trading day's opening
hour.

A big problem we had in our analysis was what to do with social media posts
which appeared outside market hours. We first decided to simply ignore them, but 
it turned out to remove a lot of observations. We finally decided to push all the 
social media information outside market hours to the next open hour. This comes 
as an assumption.[^2] 

Since our financial data is hourly, we aggregate the social data by hour. We 
then construct multiple variables from the social media data. These include
a dummy for whether there was a post, the number of posts an hour and counts
for certain words ("tariffs","trade","china"). Further we applied some simple 
sentiment analysis algorithms on the data to see if there are certain sentiments 
in his tweets that move the markets. More information and detailed process are in 
the appendix and online.

<span style="color:red"> *insert wordcloud* </span>.

```{r social plots, message=FALSE, warning=FALSE, echo=FALSE}

#find count
tweetcount_alltime = dplyr::select(data,timestamp,N)
#select time period
tweetcount = filter(tweetcount_alltime,
between(timestamp,
as.Date('2014-01-01'),
as.Date('2025-04-10')))
#plot
ggplot(tweetcount_alltime, aes(x = timestamp, y = N)) +
geom_point(color = "#253494", size = 1) +
scale_x_datetime(date_labels = "%b %Y", date_breaks = "9 month") +
labs(title = "Trump Social Media Count",
x = NULL,
y = "number of tweets/truths") +
theme_minimal(base_size = 14) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
plot.title = element_text(face = "bold", hjust = 0.5))

```


## Final Dataframe

```{r data, message=FALSE, warning=FALSE, echo=FALSE}

head(data[1:4])

head(data[5:9])

head(data[10:19])

```





¨
[^2]: For instance, if Trump tweets on Good Friday (market holiday), then the 
market will only react to this new information on Monday at 9:30 am. 

<!--chapter:end:02-data.Rmd-->

# Methodology



## ARMA-X


## VAR




<!--chapter:end:03-methodology.Rmd-->

# Discussion 

## ARMA-X Results



## VAR Results

<!--chapter:end:04-discussion.Rmd-->

# Conclusion


<!--chapter:end:05-conclusion.Rmd-->

# Bibliography



`r if (knitr::is_html_output()) '
## References {-}
'`

<!--chapter:end:06-bibliography.Rmd-->




# Appendix


<!--chapter:end:07-appendix.Rmd-->

# Cross-references {#cross}

Cross-references make it easier for your readers to find and link to elements in your book.

## Chapters and sub-chapters

There are two steps to cross-reference any heading:

1. Label the heading: `# Hello world {#nice-label}`. 
    - Leave the label off if you like the automated heading generated based on your heading title: for example, `# Hello world` = `# Hello world {#hello-world}`.
    - To label an un-numbered heading, use: `# Hello world {-#nice-label}` or `{# Hello world .unnumbered}`.

1. Next, reference the labeled heading anywhere in the text using `\@ref(nice-label)`; for example, please see Chapter \@ref(cross). 
    - If you prefer text as the link instead of a numbered reference use: [any text you want can go here](#cross).

## Captioned figures and tables

Figures and tables *with captions* can also be cross-referenced from elsewhere in your book using `\@ref(fig:chunk-label)` and `\@ref(tab:chunk-label)`, respectively.

See Figure \@ref(fig:nice-fig).

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center', fig.alt='Plot with connected points showing that vapor pressure of mercury increases exponentially as temperature increases.'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```

Don't miss Table \@ref(tab:nice-tab).

```{r nice-tab, tidy=FALSE}
knitr::kable(
  head(pressure, 10), caption = 'Here is a nice table!',
  booktabs = TRUE
)
```

<!--chapter:end:08-test.Rmd-->

