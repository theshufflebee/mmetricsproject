---
title: "daily_var"
output: html_document
---

```{r}
require("fredr")
require(here)
require(stringr)
require(dplyr)
require(ggplot2)
require(lubridate)
require(RColorBrewer)
require(wordcloud)
require(tidyr)
require(randomForest)
require(tidytext)
require(textstem)
require(tidyverse)
require(tm)
require(SnowballC)
require(quanteda.textplots)
require(quantmod)
require(alphavantager)
require(quanteda)
require(rvest)
require(httr)
require(xml2)
require(textdata)
require(sentimentr)
require(syuzhet)
require(text)
require(xts)
require(tseries)
require(vars)
require(BVAR)

truths_raw <- read.csv(here("data/political_data", "truths_new.csv"))
snp_raw <- read.csv(here("data/market_data", "SPY_24_25.csv"))

source(here("helperfunctions/truths_cleaning_function.R"))
```

```{r}
fredr_set_key(Sys.getenv("FRED_API_KEY"))
```

```{r}
# time window
start_date <- as.Date("2015-01-01")
end_date <- Sys.Date()

# VIX
vix_data <- fredr(
  series_id = "VIXCLS",
  observation_start = start_date,
  observation_end = end_date
)

# S&P500
sp500_data <- fredr(
  series_id = "SP500",
  observation_start = start_date,
  observation_end = end_date
)

# VIX
vix_df <- vix_data %>%
  mutate(vix = value) %>%
  dplyr::select(date, vix)

# S&P500
sp500_df <- sp500_data %>%
  mutate(sp500 = value) %>%
  dplyr::select(date, sp500)

# Merge into one dataframe
combined_df <- left_join(sp500_df, vix_df, by = "date")
head(combined_df)

```

```{r}
truths <-truths_processer(truths_raw) # can take one or two minutes
head(truths)
```



```{r}
# This adjust for the fact that tweets after closure only affect market in the next day (every tweet after 16:00 gets moved to next day)
truths$analysis_day <- case_when(
  truths$time_numeric <= 16 ~ as.Date(truths$day),    # before or at market close (16:00)
  truths$time_numeric > 16 ~ as.Date(truths$day) + 1, # after market close
  TRUE ~ as.Date(truths$day) # fallback
)

```

```{r}
daily_truths <- truths %>%
  group_by(analysis_day) %>%
  summarise(
    posts = paste(post, collapse = " "),  # Combine tweets on each day
    tweet_count = n(),                         # add number of days
    .groups = "drop"
  )
```


```{r}
# Join dataframes and clean up
analysis_clean_df <- daily_truths %>%
  # Shift analysis_day back by one day to reflect its influence on the market
  mutate(analysis_day_1 = analysis_day - lubridate::days(1)) %>%
  # Join with combined_df on the adjusted analysis_day
  left_join(combined_df, by = c("analysis_day" = "date")) %>%
  # Remove rows with NA values in the 'sp500' column
  drop_na(sp500) %>%
  # Rename 'analysis_day' to 'day' for consistency
  rename(day = analysis_day)
```




```{r}
analysis_clean_df <- analysis_clean_df %>%
  mutate(
    sp_ret = log(sp500 / lag(sp500)),
    vix_change = log(vix / lag(vix))
  )
```


```{r}
nrc_scores <- get_nrc_sentiment(analysis_clean_df$posts)

analysis_final_df <- bind_cols(analysis_clean_df, nrc_scores)
```

```{r}
analysis_norm_df <- analysis_final_df %>%
  mutate(
    norm_anger = anger / tweet_count,
    norm_anticipation = anticipation / tweet_count,
    norm_disgust= disgust / tweet_count,
    norm_fear = fear / tweet_count,
    norm_joy   = joy / tweet_count,
    norm_sadness = sadness / tweet_count,
    norm_surprise = surprise / tweet_count,
    norm_trust = trust / tweet_count,
    norm_negative = negative / tweet_count,
    norm_positive = positive / tweet_count
  )

analysis_norm_df <- na.omit(analysis_norm_df) #drops first row (just announcement)

```

```{r}
head(analysis_norm_df)
```




for below full vector: c("vix_change", "sp_ret", "norm_anger", "norm_anticipation", "norm_disgust", "norm_fear",  "norm_joy", "norm_sadness", "norm_surprise", "norm_trust",  "norm_negative", "norm_positive", "tweet_count")

```{r}

variables <- c("vix_change", "sp_ret","norm_negative", "norm_positive", "tweet_count")

ts_data <- xts(analysis_norm_df[, variables], 
               order.by = analysis_norm_df$day)
```

```{r}
# ADF stationary test for each column
adf_test_results <- apply(ts_data, 2, function(x) adf.test(x)$p.value) #2 means columns

# print p values (greater than 0.05 non stationry?)
adf_test_results
```


```{r}
# Determine optimal lag length using AIC
lag_selection <- VARselect(ts_data, lag.max = 15, type = "const")  # You can adjust lag.max based on your data

# View the lag length selection
lag_selection$selection
```


```{r}
# Fit the VAR model with the chosen lag length
var_model <- VAR(ts_data, p = lag_selection$selection["AIC(n)"], type = "const")

# Check the summary of the model
summary(var_model)
```

```{r}
bvar_model <- bvar(
  data = ts_data,
  lags = 7,
  hyper = set_hyper(lambda = 0.5, alpha = 3) # lambda is shrinkage, alpha is lag punishment -> lag 1 doesnt matter
)
```

```{r}
summary(bvar_model)
```

#check problem of causality -> tweets after trading hour






