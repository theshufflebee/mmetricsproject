---
title: "ARMA-X Analysis"
output:
  pdf_document: 
    toc: true
    fig_caption: yes
    latex_engine: lualatex
header-includes:
  - \usepackage{amsmath}
---
\newpage

```{r library_setup, results=FALSE, warning=FALSE, message=FALSE, echo=FALSE}
rm(list=ls())
require(tinytex) #LaTeX
require(ggplot2) #plots
require(AEC) #JP-Renne functions
require(AER) #NW formula
require(forecast) #time series stuff
require(expm) #matrix exponents
require(here) #directory finder
require(stringr) # analysis of strings, important for the detection in tweets
require(dplyr) #data management
require(lubridate) #data dates management
require(zoo) #for lagging
require(jtools) #tables
require(huxtable) #tables
require(lmtest) #reg tests
require(vroom) #for loading data
require(data.table) #for data filtering
require(sysid) #for ARMA-X modeling
require(sandwhich) #regression errors
require(stargazer) #nice reg tables
require(tidytext) #text mining
require(textstem) #lemmatization
require(quanteda) #tokenization

getwd()
#setwd("...") -> set wd at base repo folder

#load helper functions
source(here("helperfunctions/data_loaders.R"))
source(here("helperfunctions/date_selector.R"))
source(here("helperfunctions/plotters.R"))
source(here("helperfunctions/quick_arma.R"))
source(here("helperfunctions/r.vol_calculators.R"))
source(here("helperfunctions/truths_cleaning_function.R"))
source(here("helperfunctions/select_armax.R"))
```


# Data 


## Load Base Data

```{r data_setup, results=FALSE, warning=FALSE, message=FALSE}

# 1. Load Political Social Media

#contains posts from Twitter & TruthSocial
social <- read.csv(here("data/mothership", "social.csv"))

social_hourly <- read.csv(here("data/mothership", "socialhourly.csv"))


# 2. Load Financial

#S&P500
SPY <- read.csv(here("data/mothership", "SPY.csv"))

#STOXX50
VGK <- read.csv(here("data/mothership", "VGK.csv"))

#CSI 300 (China)
ASHR <- read.csv(here("data/mothership", "ASHR.CSV"))

```

```{r data_time, results=FALSE, warning=FALSE, message=FALSE}

#make posixct
SPY$timestamp = as.POSIXct(SPY$timestamp,format = "%Y-%m-%d %H:%M:%S")
VGK$timestamp = as.POSIXct(VGK$timestamp,format = "%Y-%m-%d %H:%M:%S")
ASHR$timestamp = as.POSIXct(ASHR$timestamp,format = "%Y-%m-%d %H:%M:%S")
social$timestamp = as.POSIXct(social$timestamp,format = "%Y-%m-%d %H:%M:%S")
social_hourly$timestamp = as.POSIXct(social_hourly$timestamp,format = "%Y-%m-%d %H:%M:%S")

```



## Volatility
```{r volatility}

#find hourly volatility
#NOTE: this ignores tweets made outside trading hours!!
SPY_volatility_alltime = dplyr::select(SPY,timestamp,r_vol_h)

#aggregating per hour
SPY_volatility_alltime = SPY_volatility_alltime %>%
          mutate(timestamp = floor_date(timestamp, unit = "hour")) %>%
          distinct(timestamp, .keep_all = TRUE) 
   
#select time period
SPY_volatility = filter(SPY_volatility_alltime,
                  between(timestamp, 
                          as.Date('2019-01-01'), 
                          as.Date('2025-04-10')))


```

## Number of Posts 
```{r social media count}

#find count
tweetcount_alltime = dplyr::select(social_hourly,timestamp,N)

#select time period
tweetcount = filter(tweetcount_alltime,
                  between(timestamp, 
                          as.Date('2019-01-01'), 
                          as.Date('2025-04-10')))

#plot
ggplot(tweetcount_alltime, aes(x = timestamp, y = N)) +
    geom_point(color = "#253494", size = 1) +
    scale_x_datetime(date_labels = "%b %Y", date_breaks = "9 month") +
    labs(title = "Trump Social Media Count",
         x = NULL,
         y = "number of tweets/truths") +
    theme_minimal(base_size = 14) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          plot.title = element_text(face = "bold", hjust = 0.5))
```

## Dummy for Social Media Post
```{r dummy}

#find count
tweedummy_alltime = dplyr::select(social_hourly,timestamp,dummy)

#select time period
tweetdummy = filter(tweedummy_alltime,
                  between(timestamp, 
                          as.Date('2019-01-01'), 
                          as.Date('2025-04-10')))

```

## Merge
```{r armadata merge}

#merge our dependant and independant vars
armax_data = left_join(SPY_volatility, tweetcount, by="timestamp")
armax_data = left_join(armax_data, tweetdummy, by="timestamp")

#convert NA to zeroes
armax_data$N[is.na(armax_data$N)] = 0
armax_data$dummy[is.na(armax_data$dummy)] = 0

```



# ARMA-X Models

## Find Number of Lags
```{r JPR way to check for significance of lags, results='asis'}
nb.lags <- 3 #r
count_lags <- embed(armax_data$N, nb.lags + 1)
dummy_lags <- embed(armax_data$dummy, nb.lags + 1)
colnames(count_lags) <- paste0("Lag_", 0:nb.lags)

#align volatility to match count rows (for lag)
vol_aligned <- tail(armax_data$r_vol_h, nrow(count_lags))

#choosing how many lags
# fit an ARMA(0,0,0) model with lm (with r set above)
eq <- lm(vol_aligned ~ count_lags)
eq2 <- lm(vol_aligned ~ dummy_lags)

#compute Newey-West HAC standard errors
var.cov.mat <- NeweyWest(eq, lag = 7, prewhite = FALSE)
robust_se <- sqrt(diag(var.cov.mat))
#for both
var.cov.matD <- NeweyWest(eq2, lag = 7, prewhite = FALSE)
robust_seD <- sqrt(diag(var.cov.matD))

#output table; significant lags are how many we choose
stargazer(eq, eq, type = "latex",
          column.labels = c("(no HAC)", "(HAC)"), keep.stat = "n",
          se = list(NULL, robust_se), no.space = TRUE)

#output table; significant lags are how many we choose
stargazer(eq2, eq2, type = "latex",
          column.labels = c("(no HAC)", "(HAC)"), keep.stat = "n",
          se = list(NULL, robust_seD), no.space = TRUE)

```

## Tweet Count on Volatility by hour
```{r ARMA-X count hourly volatility}

#find best armax model and fit
armax_fit <- select_armax(armax_data$r_vol_h, armax_data$N, 
                       max_p = 5, max_q = 5, max_r = 5, criterion = "AIC")

summary(armax_fit$model) 
armax_fit$ICplot
armax_fit$params

```


## Tweet Dummy on Volatility by hour
```{r ARMA-X dummy hourly}

#find best armax model and fit
armax_fit <- select_armax(armax_data$r_vol_h, armax_data$dummy, 
                       max_p = 5, max_q = 5, max_r = 5, criterion = "AIC")

summary(armax_fit$model) 
armax_fit$ICplot
armax_fit$params

```














